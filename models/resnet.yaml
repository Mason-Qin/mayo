---
model:
    layers:
        _norm: &norm
            type: batch_norm
            activation_fn: tf.nn.relu
            scale: true
            decay: 0.997
            epsilon: 0.00001
        _conv2d_same: &conv2d_same
            type: convolution
            _kernel_effective: !arith $(.kernel_size) - 1
            _pad_begin: !arith $(._kernel_effective) // 2
            _pad_end: !arith $(._kernel_effective) - $(._pad_begin)
            padding: !arith >
                [[$(._pad_begin), $(._pad_end)]] * 2
                if $(.stride) == 1 else 'VALID'
        _bottleneck: &bottleneck
            type: module
            kwargs:
                depth: null
                depth_bottleneck: null
                stride: null
                shortcut: null
            layers:
                norm: *norm
                conv_shortcut:
                    type: convolution
                    kernel_size: 1
                    stride: ^stride
                    num_outputs: ^depth
                    normalizer_fn: null
                    activation_fn: null
                pool_shortcut:
                    type: max_pool
                    kernel_size: 1
                    stride: ^stride
                conv1: &bottleneck_conv1
                    type: convolution
                    kernel_size: 1
                    stride: 1
                    num_outputs: ^depth_bottleneck
                conv2: {<<: *conv2d_same, kernel_size: 3, stride: ^stride}
                conv3:
                    <<: *bottleneck_conv1
                    normalizer_fn: null
                    activation_fn: null
                add: {type: add}
            graph:
                - {from: input, with: norm, to: preact}
                - {from: preact, with: ^(shortcut)_shortcut, to: shortcut}
                - {from: preact, with: [conv1, conv2, conv3], to: residual}
                - {from: [shortcut, residual], with: [add], to: output}
