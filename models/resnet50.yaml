---
dataset:
    background_class: {use: true}
    preprocess:
        shape:
            height: 224
            width: 224
            channels: 3
        validate: null
        final_cpu:
            - {type: subtract_channel_means}
            - {type: linear_map, scale: 255.0}
model:
    name: resnet50
    description:
        ResNet50 implementation from::
            https://github.com/tensorflow/models/blob/master/research/slim/nets/resnet_v2.py
    layers:
        _conv: &conv
            type: convolution
            _initializer: &initializer
                type: tensorflow.variance_scaling_initializer
            _regularizer: &regularizer
                type: tensorflow.contrib.layers.l2_regularizer
                scale: 0.0001
            activation_fn: tf.nn.relu
            normalizer_fn: &normalizer
                type: tensorflow.contrib.slim.batch_norm
                scale: true
                decay: 0.997
                epsilon: 0.00001
        _conv_same: &conv_same
            <<: *conv
            _kernel_effective: !arith $(.kernel_size) - 1
            _pad_begin: !arith $(._kernel_effective) // 2
            _pad_end: !arith $(._kernel_effective) - $(._pad_begin)
            padding: !arith >
                [[$(._pad_begin), $(._pad_end)]] * 2
                if $(.stride) == 1 else 'VALID'
        _bottleneck: &bottleneck
            type: module
            kwargs: {depth: null, stride: null, shortcut: null}
            layers:
                norm: &norm
                    <<: *normalizer
                    type: batch_norm
                    activation_fn: tf.nn.relu
                conv_shortcut:
                    <<: *conv
                    kernel_size: 1
                    stride: ^(stride)
                    num_outputs: ^(depth)
                    normalizer_fn: null
                    activation_fn: null
                pool_shortcut:
                    type: max_pool
                    kernel_size: 1
                    stride: ^stride
                conv1: &bottleneck_conv1
                    <<: *conv
                    kernel_size: 1
                    stride: 1
                    num_outputs: !arith ^(depth) / 4
                conv2:
                    <<: *conv_same
                    kernel_size: 3
                    stride: ^stride
                    num_outputs: !arith ^(depth) / 4
                conv3:
                    <<: *bottleneck_conv1
                    num_outputs: ^(depth)
                    normalizer_fn: null
                    activation_fn: null
                add: {type: add}
            graph:
                - {from: input, with: norm, to: preact}
                - {from: preact, with: ^(shortcut)_shortcut, to: shortcut}
                - {from: preact, with: [conv1, conv2, conv3], to: residual}
                - {from: [shortcut, residual], with: [add], to: output}
        # root block
        conv1: {<<: *conv_same, kernel_size: 7, stride: 2, num_outputs: 64}
        pool1: {type: max_pool, kernel_size: 3, stride: 2}
        block1_1: {<<: *bottleneck, shortcut: conv, depth: 256, stride: 1}
        block1_2: {<<: *bottleneck, shortcut: pool, depth: 256, stride: 1}
        block1_3: {<<: *bottleneck, shortcut: pool, depth: 256, stride: 2}
        block2_1: {<<: *bottleneck, shortcut: conv, depth: 512, stride: 1}
        block2_2: {<<: *bottleneck, shortcut: pool, depth: 512, stride: 1}
        block2_3: {<<: *bottleneck, shortcut: pool, depth: 512, stride: 1}
        block2_4: {<<: *bottleneck, shortcut: pool, depth: 512, stride: 2}
        block3_1: {<<: *bottleneck, shortcut: conv, depth: 1024, stride: 1}
        block3_2: {<<: *bottleneck, shortcut: pool, depth: 1024, stride: 1}
        block3_3: {<<: *bottleneck, shortcut: pool, depth: 1024, stride: 1}
        block3_4: {<<: *bottleneck, shortcut: pool, depth: 1024, stride: 1}
        block3_5: {<<: *bottleneck, shortcut: pool, depth: 1024, stride: 1}
        block3_6: {<<: *bottleneck, shortcut: pool, depth: 1024, stride: 2}
        block4_1: {<<: *bottleneck, shortcut: conv, depth: 2048, stride: 1}
        block4_2: {<<: *bottleneck, shortcut: pool, depth: 2048, stride: 1}
        block4_3: {<<: *bottleneck, shortcut: pool, depth: 2048, stride: 2}
        postnorm: {<<: *norm}
        pool5: {type: average_pool, kernel_size: [7, 7]}
        logits:
            <<: *conv
            kernel_size: 1
            activation_fn: null
            normalizer_fn: null
        squeeze: {type: squeeze, axis: [1, 2]}
    graph:
        from: input
        with: [
            conv1, pool1,
            block1_1, block1_2, block1_3,
            block2_1, block2_2, block2_3, block2_4,
            block3_1, block3_2, block3_3, block3_4, block3_5, block3_6,
            block4_1, block4_2, block4_3,
            postnorm, pool5, logits, squeeze]
        to: output
