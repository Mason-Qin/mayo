---
dataset:
    background_class: {use: false}
    preprocess:
        shape:
            height: 32
            width: 32
            channels: 3
        validate:
            - {type: crop_or_pad}
        final_cpu:
            - {type: standardize_image}
model:
    name: zipf_hadamard
    description: Zipf-Hadamard CifarNet
    layers:
        _conv: &conv
            type: convolution
            padding: same
            kernel_size: 3
            weights_initializer:
                type: tensorflow.variance_scaling_initializer
            weights_regularizer:
                type: tensorflow.contrib.layers.l2_regularizer
                scale: 0.0001
            normalizer_fn: tensorflow.contrib.slim.batch_norm
            normalizer_params:
                scale: true
                decay: 0.9997
                epsilon: 0.001
        _zh: &zh
            <<: *conv
            type: hadamard_convolution
            block: true
        conv0: {<<: *conv, num_outputs: 1024, padding: valid}
        conv1: {<<: *zh, num_outputs: 1024}
        conv2: {<<: *zh, num_outputs: 1024, stride: 2}
        conv3: {<<: *zh, num_outputs: 1024}
        conv4: {<<: *zh, num_outputs: 1024}
        conv5: {<<: *zh, num_outputs: 1024, stride: 2}
        conv6: {<<: *zh, num_outputs: 1024}
        conv7: {<<: *zh, num_outputs: 1024}
        pool7: {type: average_pool, kernel_size: 8}
        logits:
            <<: *conv
            type: convolution
            kernel_size: 1
            num_outputs: num_classes
            activation_fn: null
            normalizer_fn: null
        squeeze: {type: squeeze, axis: [1, 2]}
    graph:
        from: input
        with: [
            conv0, conv1, conv2, conv3, conv4, conv5, conv6,
            conv7, pool7, logits, squeeze]
        to: output
