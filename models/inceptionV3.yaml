---
dataset:
    background_class: {use: false}
    preprocess:
        shape:
            height: 299
            width: 299
            channels: 3
        validate: []
        final:
            - {type: normalize_channels}
model:
    name: inceptionV3
    description: |
        This implementation is based on::
          Rethinking the Inception Architecture for Computer Vision
          https://arxiv.org/abs/1512.00567
        We use the following reference models::
          https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/nets/inception_v3.py
    layers:
        _init: &init
            biases_initializer:
                type: tensorflow.constant_initializer
                value: 0.01
        _conv: &conv
            type: convolution
            padding: valid
            kernel_size: 3
            stride: 1
            # weight_initializer defaults to xavier
            weights_regularizer:
                type: tensorflow.contrib.layers.l2_regularizer
                scale: 0.0005
            <<: *init
        _fc: &fc
            type: fully_connected
            weights_initializer:
                type: tensorflow.truncated_normal_initializer
                stddev: 0.09
            <<: *init
        _mixed5: &mixed5
          type: module
            kwargs: [squeeze_depth, expand_depth]
            layers:
                b0: &branch
                    <<: *conv
                    kernel_size: 1
                    num_outputs: 64
                b1_1x1:
                    <<: *branch
                    num_outputs: 48
                b1_5x5:
                    <<: *conv
                    kernel_size: 5
                    num_outputs: 64
                b2_1x1:
                    <<: *branch
                    num_outputs: 64
                b2_3x3b:
                    <<: *conv
                    kernel_size: 3
                    num_outputs: 96
                b2_3x3c:
                    <<: *conv
                    kernel_size: 3
                    num_outputs: 96
                b3_avg_pool:
                    type: average_pool
                    kernel_size: 3
                    stride: 1
                    padding: valid
                b3_1x1:
                    <<: *branch
                    num_outputs: 32
                concat:
                    type: concat
                    axis: 3
            graph:
                - {from: input, with: b0, to: b0_out}
                - {from: input, with: [b1_1x1, b1_5x5], to: b1_out}
                - {from: input, with: [b2_1x1, b2_3x3b, b2_3x3c] , to: b2_out}
                - {from: input, with: [b3_avg_pool, b3_1x1], to: b3_out}
                - {from: [b0_out, b1_out, b2_out, b3_out], with: concat, to: output}
        _mixed6a: &mixed6a
          type: module
            layers:
                b0:
                    <<: *conv
                    kernel_size: 3
                    stride: 2
                    num_outputs: 384
                b1_1x1:
                    <<: *branch
                    num_outputs: 64
                b1_3x3b:
                    <<: *conv
                    kernel_size: 3
                    num_outputs: 96
                b1_3x3c:
                    <<: *conv
                    kernel_size: 3
                    stride: 2
                    num_outputs: 96
                b2_max_pool:
                    type: max_pool
                    kernel_size: 3
                    stride: 2
                    padding: valid
                concat:
                    type: concat
                    axis: 3
            graph:
                - {from: input, with: b0, to: b0_out}
                - {from: input, with: [b1_1x1, b1_3x3b, b1_3x3c], to: b1_out}
                - {from: input, with: b2_max_pool, to: b2_out}
                - {from: [b0_out, b1_out, b2_out], with: concat, to: output}
        _mixed6bc: &mixed6bc
          type: module
          kwargs: [depth]
            layers:
                b0:
                    <<: *conv
                    kernel_size: 1
                    num_outputs: 192
                b1_1x1:
                    <<: *branch
                    num_outputs: ^depth
                b1_1x7:
                    <<: *conv
                    kernel_size: [1,7]
                    num_outputs: ^depth
                b1_7x1:
                    <<: *conv
                    kernel_size: [7,1]
                    num_outputs: 192
                b2_1x1:
                    <<: *branch
                    num_outputs: ^depth
                b2_1x7a:
                    <<: *conv
                    kernel_size: [7,1]
                    num_outputs: ^depth
                b2_7x1a:
                    <<: *conv
                    kernel_size: [1,7]
                    num_outputs: ^depth
                b2_1x7b:
                    <<: *conv
                    kernel_size: [7,1]
                    num_outputs: ^depth
                b2_7x1b:
                    <<: *conv
                    kernel_size: [1,7]
                    num_outputs: 192
                b3_avg_pool:
                    type: average_pool
                    kernel_size: 3
                    padding: valid
                b3_1x1:
                    <<: *conv
                    kernel_size: 1
                    num_outputs: 192
                concat:
                    type: concat
                    axis: 3
            graph:
                - {from: input, with: b0, to: b0_out}
                - {from: input, with: [b1_1x1, b1_1x7, b1_7x1], to: b1_out}
                - {from: input, with: [b2_1x1, b2_7x1a, b2_1x7a, b2_7x1b, b2_1x7b], to: b2_out}
                - {from: input, with: [b3_avg_pool, b3_1x1], to: b3_out}
                - {from: [b0_out, b1_out, b2_out, b3_out], with: concat, to: output}
        _mixed7a: &mixed7a
          type: module
            layers:
                b0_1x1:
                    <<: *branch
                    num_outputs: 320
                b0_3x3: &b33
                    <<: *conv
                    kernel_size: [3,3]
                    stride: 2
                    num_outputs: 320
                b1_1x1:
                    <<: *branch
                    num_outputs: 192
                b1_1x7:
                    <<: *conv
                    kernel_size: [1,7]
                    num_outputs: 192
                b1_7x1:
                    <<: *conv
                    kernel_size: [7,1]
                    num_outputs: 192
                b1_3x3:
                    <<: *b33
                    num_outputs: 192
                b2_max_pool:
                    type: max_pool
                    kernel_size: 3
                    stride: 2
                    padding: valid
                concat:
                    type: concat
                    axis: 3
            graph:
                - {from: input, with: [b0_1x1, b0_3x3], to: b0_out}
                - {from: input, with: [b1_1x1, b1_1x7, b1_7x1, b1_3x3], to: b1_out}
                - {from: input, with: [b2_max_pool, b3_1x1], to: b2_out}
        _mixed7b: &mixed7b
          type: module
          kwargs: [depth]
            layers:
                b0_1x1:
                    <<: *branch
                    num_outputs: 320
                b1_1x1:
                    <<: *branch
                    num_outputs: 384
                b1_1x3:
                    <<: *conv
                    kernel_size: [1,3]
                    num_outputs: 384
                b1_3x1:
                    <<: *conv
                    kernel_size: [3,1]
                    num_outputs: 384
                b2_1x1:
                    <<: *branch
                    num_outputs: 448
                b2_3x3:
                    <<: *conv
                    kernel_size: [3,3]
                    num_outputs: 384
                b2_1x3:
                    <<: *conv
                    kernel_size: [1,3]
                    num_outputs: 384
                b2_3x1:
                    <<: *conv
                    kernel_size: [3,1]
                    num_outputs: 384
                b3_avg_pool:
                    type: average_pool
                    kernel_size: 3
                    padding: valid
                b3_1x1:
                    <<: *branch
                    num_outputs: 192
                concat:
                    type: concat
                    axis: 3
            graph:
                - {from: input, with: b0_1x1, to: b0_out}
                - {from: input, with: [b1_1x1, b1_1x3], to: b1_tmp1}
                - {from: input, with: [b1_1x1,  b1_3x1], to: b1_tmp2}
                - {from: [b1_tmp1, b1_tmp2], with: concat, to: b1_out}
                - {from: input, with: [b2_1x1, b2_3x3, b2_1x3], to: b2_tmp1}
                - {from: input, with: [b2_1x1, b2_3x3, b2_3x1], to: b2_tmp2}
                - {from: [b2_tmp1, b2_tmp2], with: concat, to: b2_out}
                - {from: input, with: [b3_avg_pool, b3_1x1], to: b3_out}
                - {from: [b0_out, b1_out, b2_out, b3_out], with: concat, to: output}

        conv1a: {<<: *conv, stride: 2, num_outputs: 32}
        conv2a: {<<: *conv, stride: 1, num_outputs: 32}
        conv2b: {<<: *conv, stride: 1, padding: same, num_outputs: 64}
        pool3a: {type: max_pool, kernel_size: 3, stride: 2, padding: valid}
        conv3b: {<<: *conv, kernel_size: 1, stride: 1, num_outputs: 80}
        conv4a: {<<: *conv, stride: 1, num_outputs: 192}
        pool5a: {type: max_pool, kernel_size: 3, stride: 2, padding: valid}
        mixed5b: {<<: mixed5}
        mixed5c: {<<: mixed5}
        mixed5d: {<<: mixed5}
        mixed6a: {<<: mixed6a}
        mixed6b: {<<: mixed6bc, depth: 128}
        mixed6c: {<<: mixed6bc, depth: 160}
        mixed6d: {<<: mixed6bc, depth: 160}
        mixed63: {<<: mixed6bc, depth: 192}
        mixed7a: {<<: mixed7a}
        mixed7b: {<<: mixed7b}
        mixed7c: {<<: mixed7c}
        logits: {type: squeeze, axis: [1, 2]}
    graph:
        from: images
        with:
            [conv1, pool1,
             fire2, fire3, fire4, pool4,
             fire5, fire6, fire7, fire8, pool8,
             fire9, dropout9, conv10, pool10, logits]
        to: logits
