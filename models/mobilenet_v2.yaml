---
dataset:
    task:
        background_class: {use: true}
        preprocess:
            shape:
                height: 224
                width: 224
                channels: 3
            validate: {type: central_crop, fraction: 0.875}
            final_cpu:
                - {type: resize, fill: false}
                - {type: linear_map, scale: 2.0, shift: -1.0}
model:
    name: mobilenet_v2
    description:
        MobileNet implementation from::
            https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py
    layers:
        _conv: &conv
            type: convolution
            kernel_size: 3
            stride: 1
            padding: same
            normalizer_fn: tensorflow.contrib.slim.batch_norm
            normalizer_params:
                center: true
                scale: true
                decay: 0.997
                epsilon: 0.001
            weights_initializer:
                type: tensorflow.truncated_normal_initializer
                stddev: 0.09
            activation_fn: tensorflow.nn.relu6
        _inverted_bottleneck: &ibn
            type: module
            kwargs:
                num_expand: null
                num_outputs: null
                stride: null
                residual: true
            layers:
                expand:
                    <<: *conv
                    kernel_size: 1
                    num_outputs: ^(num_expand)
                depthwise:
                    <<: *conv
                    type: depthwise_convolution
                    stride: ^(stride)
                project:
                    <<: *conv
                    kernel_size: 1
                    num_outputs: ^(num_outputs)
                    activation_fn: null
                identity_shortcut: {type: identity}
                add: {type: add}
            graph:
                - {from: input, with: [expand, depthwise, project], to: conv}
                - {from: [conv, input], with: add, to: residual}
                - from: !arith >
                      'residual' if ^(residual) and ^(stride) == 1 else 'conv'
                  with: null
                  to: output
        prep: {type: identity}
        conv0: {<<: *conv, stride: 2, num_outputs: 32}
        ibn0:
            <<: *ibn
            num_expand: 32
            num_outputs: 16
            stride: 1
            residual: false
            graph: {from: input, with: [depthwise, project], to: output}
        ibn1: {<<: *ibn, num_expand: 96, num_outputs: 24, stride: 2}
        ibn2: {<<: *ibn, num_expand: 144, num_outputs: 24, stride: 1}
        ibn3: {<<: *ibn, num_expand: 144, num_outputs: 32, stride: 2}
        ibn4: {<<: *ibn, num_expand: 192, num_outputs: 32, stride: 1}
        ibn5: {<<: *ibn, num_expand: 192, num_outputs: 32, stride: 1}
        ibn6: {<<: *ibn, num_expand: 192, num_outputs: 64, stride: 2}
        ibn7: {<<: *ibn, num_expand: 384, num_outputs: 64, stride: 1}
        ibn8: {<<: *ibn, num_expand: 384, num_outputs: 64, stride: 1}
        ibn9: {<<: *ibn, num_expand: 384, num_outputs: 64, stride: 1}
        ibn10:
            <<: *ibn
            num_expand: 384
            num_outputs: 96
            stride: 1
            residual: false
        ibn11: {<<: *ibn, num_expand: 576, num_outputs: 96, stride: 1}
        ibn12: {<<: *ibn, num_expand: 576, num_outputs: 96, stride: 1}
        ibn13: {<<: *ibn, num_expand: 576, num_outputs: 160, stride: 2}
        ibn14: {<<: *ibn, num_expand: 960, num_outputs: 160, stride: 1}
        ibn15: {<<: *ibn, num_expand: 960, num_outputs: 160, stride: 1}
        ibn16:
            <<: *ibn
            num_expand: 960
            num_outputs: 320
            stride: 1
            residual: false
        conv1: {<<: *conv, kernel_size: 1, stride: 1, num_outputs: 1280}
        pool: {type: average_pool, kernel_size: global, stride: 1}
        dropout: {type: dropout, keep_prob: 0.8}
        fc:
            <<: *conv
            kernel_size: 1
            num_outputs: $(dataset.task.num_classes)
            normalizer_fn: null
            activation_fn: null
        logits: {type: squeeze, axis: [1, 2]}
    graph:
        from: input
        with: [
            prep, conv0,
            ibn0, ibn1, ibn2, ibn3, ibn4,
            ibn5, ibn6, ibn7, ibn8, ibn9,
            ibn10, ibn11, ibn12, ibn13, ibn14,
            ibn15, ibn16, conv1,
            pool, dropout, fc, logits]
        to: output
