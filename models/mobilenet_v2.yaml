---
dataset:
    task:
        background_class: {use: true}
        preprocess:
            shape:
                height: 224
                width: 224
                channels: 3
            validate: {type: central_crop, fraction: 0.875}
            final_cpu:
                - {type: resize, fill: false}
                - {type: linear_map, scale: 2.0, shift: -1.0}
model:
    name: mobilenet_v2
    description:
        MobileNet implementation from::
            https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py
    layers:
        _conv: &conv
            type: convolution
            kernel_size: 3
            stride: 1
            padding: same
            normalizer_fn: tensorflow.contrib.slim.batch_norm
            normalizer_params:
                center: true
                scale: true
                decay: 0.9997
                epsilon: 0.001
            weights_initializer:
                type: tensorflow.truncated_normal_initializer
                stddev: 0.09
            activation_fn: tensorflow.nn.relu6
        _inverted_bottleneck: &ibn
            type: module
            kwargs:
                factor: 6
                num_outputs: null
                stride: null
                residual: true
            layers:
                pointwise:
                    <<: *conv
                    kernel_size: 1
                    num_outputs: &ibn_outputs !arith ^(num_outputs) * ^(factor)
                depthwise:
                    <<: *conv
                    type: depthwise_convolution
                    stride: ^(stride)
                pointwise_linear:
                    <<: *conv
                    kernel_size: 1
                    num_outputs: *ibn_outputs
                    activation_fn: null
                identity_shortcut: {type: identity}
                add: {type: add}
            graph:
                - from: input
                  with: [pointwise, depthwise, pointwise_linear]
                  to: conv
                - {from: [conv, input], with: add, to: residual}
                - from: !arith >
                      'residual' if ^(residual) and ^(stride) == 1 else 'conv'
                  with: null
                  to: output
        prep: {type: identity}
        conv0: {<<: *conv, stride: 2, num_outputs: 32}
        conv1:
            {<<: *ibn, num_outputs: 16, stride: 1, factor: 1, residual: false}
        conv2: {<<: *ibn, num_outputs: 24, stride: 2}
        conv3: {<<: *ibn, num_outputs: 24, stride: 1}
        conv4: {<<: *ibn, num_outputs: 32, stride: 2}
        conv5: {<<: *ibn, num_outputs: 32, stride: 1}
        conv6: {<<: *ibn, num_outputs: 32, stride: 1}
        conv7: {<<: *ibn, num_outputs: 64, stride: 2}
        conv8: {<<: *ibn, num_outputs: 64, stride: 1}
        conv9: {<<: *ibn, num_outputs: 64, stride: 1}
        conv10: {<<: *ibn, num_outputs: 64, stride: 1}
        conv11: {<<: *ibn, num_outputs: 96, stride: 1, residual: false}
        conv12: {<<: *ibn, num_outputs: 96, stride: 1}
        conv13: {<<: *ibn, num_outputs: 96, stride: 1}
        conv14: {<<: *ibn, num_outputs: 160, stride: 2}
        conv15: {<<: *ibn, num_outputs: 160, stride: 1}
        conv16: {<<: *ibn, num_outputs: 160, stride: 1}
        conv17: {<<: *ibn, num_outputs: 320, stride: 1, residual: false}
        conv18: {<<: *conv, kernel_size: 1, stride: 1, num_outputs: 1280}
        pool: {type: average_pool, kernel_size: global, stride: 1}
        dropout: {type: dropout, keep_prob: 0.999}
        fc:
            <<: *conv
            kernel_size: 1
            num_outputs: $(dataset.task.num_classes)
            normalizer_fn: null
            activation_fn: null
        logits: {type: squeeze, axis: [1, 2]}
    graph:
        from: input
        with: [
            prep, conv0,
            conv1, conv2, conv3, conv4, conv5,
            conv6, conv7, conv8, conv9, conv10,
            conv11, conv12, conv13, conv14, conv15, conv16, conv17, conv18,
            pool, dropout, fc, logits]
        to: output
