#!/usr/bin/env python3
import os
import re

import yaml
import numpy as np
from docopt import docopt

import mayo
from mayo.log import log


os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'


class BaseImporter(object):
    def __init__(self, file):
        super().__init__()
        log.key('Importing with {}...'.format(self.__class__.__name__))
        self.var_to_shape, self.var_to_tensor = self._import(file)

    @staticmethod
    def _import(file):
        raise NotImplementedError


class NumpyImporter(BaseImporter):
    _encoding = 'ASCII'

    @classmethod
    def _import(cls, file):
        var_to_tensor = np.load(file, encoding=cls._encoding).item()
        var_to_shape = {k: list(v.shape) for k, v in var_to_tensor.items()}
        return var_to_shape, var_to_tensor


class CheckpointImporter(BaseImporter):
    @staticmethod
    def _import(file):
        import tensorflow as tf
        reader = tf.train.NewCheckpointReader(file)
        var_to_shape = reader.get_variable_to_shape_map()
        var_to_tensor = {}
        for v in var_to_shape:
            var_to_tensor[v] = reader.get_tensor(v)
        return var_to_shape, var_to_tensor


class PyTorchImporter(BaseImporter):
    @staticmethod
    def _permute(tensor):
        """
        PyTorch tensors requires us to permute them, as the ordering is
        different from tensorflow.
        Convolution:
            torch:      [out_maps, in_maps, kernel_h, kernel_w]
            tensorflow: [kernel_h, kernel_w, in_maps, out_maps]
        FC:
            torch:      [out, in]
            tensorflow: [in, out]
        """
        dim = len(tensor.size())
        tensor = tensor.data.numpy()
        if dim == 2:
            permute = (1, 0)
        elif dim == 4:
            permute = (2, 3, 1, 0)
        else:
            return tensor
        return np.transpose(tensor, permute)

    def _import(self, file):
        from torch import load
        raw = load(file)
        var_to_shape = {}
        var_to_tensor = {}
        for k, v in raw.items():
            tensor = self._permute(v)
            var_to_tensor[k] = tensor
            var_to_shape[k] = list(tensor.shape)
        return var_to_shape, var_to_tensor


class BaseExporter(object):
    def __init__(self, var_to_tensor, rules):
        super().__init__()
        self.var_to_tensor = self._rename(var_to_tensor, rules)

    @staticmethod
    def _rename_map(variables, rules):
        vvmap = {}
        for v in variables:
            nv = v
            for pattern, replacement in rules.items():
                if replacement is None:
                    if re.findall(pattern, nv):
                        break
                else:
                    nv = re.sub(pattern, replacement, nv)
            else:
                vvmap[v] = nv
        return vvmap

    def _rename(self, var_to_tensor, rules):
        log.key('Renaming variables...')
        rename_map = self._rename_map(var_to_tensor, rules)
        new_var_to_tensor = {}
        for v in var_to_tensor:
            try:
                nv = rename_map[v]
            except KeyError:
                log.info('Skipping {!r} as it is not required'.format(v))
                continue
            if nv != v:
                log.info('Renamed {!r} as {!r}.'.format(v, nv))
            else:
                log.info('{!r} is not renamed.'.format(v))
            new_var_to_tensor[nv] = var_to_tensor[v]
        return new_var_to_tensor

    def export(self, file, dry_run=False):
        if dry_run:
            log.key('Dry run, not actually saving.')
            return
        log.key('Exporting with {}...'.format(self.__class__.__name__))
        self._export(file)

    def _export(self, file):
        raise NotImplementedError


class NumpyExporter(BaseExporter):
    def _export(self, file):
        np.save(file, self.var_to_tensor)


class CheckpointExporter(BaseExporter):
    def _export(self, file):
        import tensorflow as tf
        session = tf.Session()
        new_vars = []
        log.info('Instantiating variables...')
        with session.as_default():
            for var, tensor in self.var_to_tensor.items():
                new_vars.append(tf.Variable(tensor, name=var))
        log.info('Saving checkpoint with renamed variables...')
        saver = tf.train.Saver()
        session.run(tf.variables_initializer(new_vars))
        saver.save(session, file)


_importers = {
    '': CheckpointImporter,
    '.npy': NumpyImporter,
    '.pth': PyTorchImporter,
}
_exporters = {
    '': CheckpointExporter,
    '.npy': NumpyExporter,
}


_USAGE = """
The mayo checkpoint helper.
Usage:
    {executable} <from_file> info
    {executable} <from_file> export <to_file> [options]

Arguments:
    * <from_file> can be a file that is either:
{importers}
    * <to_file> can be one of:
{exporters}

Options:
    --dry-run           Performs a dry run, not actually changing anything
                        but shows things to be changed.
    --rules=<yaml>      Replaces keys with new keys given in the specified YAML
                        file using `re.sub`.  The YAML file should be written
                        as ordered mappings with `<pattern>: <replacement>`,
                        which we will apply the substitution in the order of
                        mapping.
"""


def usage():
    def format_porters(porters):
        descs = []
        for index, (suffix, porter) in enumerate(porters.items()):
            if not suffix:
                desc = 'a file without a suffix'
            else:
                desc = 'a {!r} file'.format(suffix)
            final = ';'
            if index == len(porters) - 2:
                final = '; or'
            elif index == len(porters) - 1:
                final = '.'
            descs.append(
                '{}- {} ({}){}'.format(' ' * 8, desc, porter.__name__, final))
        return '\n'.join(descs)

    importers = format_porters(_importers)
    exporters = format_porters(_exporters)
    return _USAGE.format(
        executable=__file__, importers=importers, exporters=exporters)


def _porter(file, porters):
    name, suffix = os.path.splitext(file)
    try:
        return porters[suffix]
    except KeyError:
        raise ValueError('Unrecognized suffix {!r}'.format(suffix))


def main():
    args = docopt(usage(), version=mayo.__version__)
    from_file = args['<from_file>']
    importer_cls = _porter(from_file, _importers)
    importer = importer_cls(from_file)
    if args['info']:
        print(yaml.dump(importer.var_to_shape))
    elif args['export']:
        rules = args['--rules']
        with open(rules, 'r') as f:
            rules = yaml.load(f)
        to_file = args['<to_file>']
        exporter_cls = _porter(to_file, _exporters)
        exporter = exporter_cls(importer.var_to_tensor, rules)
        exporter.export(to_file, args['--dry-run'])
    else:
        raise TypeError('Do not know what we should do.')


if __name__ == "__main__":
    main()
